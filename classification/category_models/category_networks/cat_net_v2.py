import tensorflow_datasets as tfds
import pandas as pd
import tensorflow as tf

from keras import layers
from keras import losses
from keras.layers import TextVectorization, Dense
from keras.models import Sequential
from typing import List

from sklearn.metrics import accuracy_score

from .base_category_network import BaseCategoryNetwork
from ...preprocessing import Category
from ...preprocessing.categorize_prepare import create_feature_list, get_df_from_feature_list_str_features, \
    encode_class_values

tfds.disable_progress_bar()
"""
Because of my previous problems, I'll keep this so I can always reset to this step or at least refer back 
to the minimum working version.
"""
class CategoryNetworkV2(BaseCategoryNetwork):

    def __init__(self, name: str, **kwargs):
        super().__init__(name=name, version='v2', description='Working Base Classificator.')

    """
    Method loads the saved trained model and predicts the categories for the input web_ids.
    Preparation of the input generated by the web_ids is handled through the method 
    get_df_from_feature_list_inkl_keyword_result which returns a dataframe with the web_ids as index.
    """
    def predict(self, web_ids: List[str]) -> List[Category]:
        self.load()
        feature_dict = get_df_from_feature_list_str_features(create_feature_list(web_ids), web_ids)
        X = pd.get_dummies(feature_dict.drop(['true_category', 'web_id'], axis=1))
        #y_test = feature_dict['true_category'].apply(lambda x: int(x))
        enc, y_test = encode_class_values(feature_dict['true_category'])
        # loss, accuracy = self.model.predict(feature_dict)
        # print("Accuracy: {:2.2%}".format(binary_accuracy))
        y_hat = self.model.predict(X)
        #print(y_hat)
        y_hat
        # y_hat = model.predict(X_test)
        #y_hat = [0 if val < 0.5 else 1 for val in y_hat] #for 0-1 classes
        #accuracy_score(y_test, y_hat)
        # todo reformatting the categorys back from int-matrix (encoded) -> str
        return y_hat


    """
    Method is base method of a classificator method and forwards into the predict method.
    """
    def classification(self, web_ids: List[str]) -> List[Category]:
        return self.predict(web_ids)


    """
    Method is base method of a classificator method and forwards into the predict method.
    Preparation of the input generated by the web_ids is handled through the method 
    get_df_from_feature_list_inkl_keyword_result which returns a dataframe with the web_ids as index.
    The keras model built here, has 8 output classes (9 will be none for keyword based), uses softmax as the last layer.
    Optimizer is adam, SparseCategoricalCrossentropy, and the accuracy metrics.
    Training length here is only used for testing: epochs=24, batch_size=32
    """
    def train(self, web_ids: List[str]) -> None:
        feature_dict = get_df_from_feature_list_str_features(create_feature_list(web_ids), web_ids)
        X_train = pd.get_dummies(feature_dict.drop(['true_category', 'web_id'], axis=1))
       # encoder, y_train = encode_class_values(feature_dict['true_category'])
        y_train = feature_dict['true_category']
        model = Sequential()
        model.add(Dense(units=32, activation='relu', input_dim=len(X_train.columns)))
        model.add(Dense(units=64, activation='relu'))
        model.add(Dense(units=64, activation='relu'))
        model.add(Dense(units=9, activation='softmax'))  # softmax

        model.compile(
            loss=losses.SparseCategoricalCrossentropy(from_logits=True),
            optimizer='adam',
            metrics='accuracy')
        model.fit(X_train, y_train, epochs=24, batch_size=32)
        self.model = model
        self.save()
        # (number of inputs + 1 output)/2 = #hiddenLayers
        pass
